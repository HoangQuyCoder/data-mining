from DrissionPage import ChromiumPage, ChromiumOptions
import time
import random
import math
import logging
import datetime
from crawl.base_crawler import crawl_all_generic
from crawl.settings import (
    SHOPEE_RAW_DIR,
    SHOPEE_CATEGORY_DIR,
    MAX_PAGES,
    SLEEP_MIN,
    SLEEP_MAX
)

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# --- DANH M·ª§C SHOPEE ---
SHOPEE_CATEGORIES = [
    {"name": "ƒêi·ªán tho·∫°i", "url": "https://shopee.vn/search?keyword=ƒêi·ªán%20tho·∫°i"},
    {"name": "Laptop", "url": "https://shopee.vn/search?keyword=Laptop"},
    {"name": "Th·ªùi trang n·ªØ", "url": "https://shopee.vn/search?keyword=Th·ªùi%20trang%20n·ªØ"},
    {"name": "Th·ªùi trang nam", "url": "https://shopee.vn/search?keyword=Th·ªùi%20trang%20nam"},
    {"name": "Gi√†y d√©p", "url": "https://shopee.vn/search?keyword=Gi√†y%20d√©p"},
    {"name": "T√∫i x√°ch", "url": "https://shopee.vn/search?keyword=T√∫i%20x√°ch"},
    {"name": "ƒê·ªìng h·ªì", "url": "https://shopee.vn/search?keyword=ƒê·ªìng%20h·ªì"},
    {"name": "Trang s·ª©c", "url": "https://shopee.vn/search?keyword=Trang%20s·ª©c"},
    {"name": "M·ªπ ph·∫©m", "url": "https://shopee.vn/search?keyword=M·ªπ%20ph·∫©m"},
    {"name": "ChƒÉm s√≥c da", "url": "https://shopee.vn/search?keyword=ChƒÉm%20s√≥c%20da"},
    {"name": "M√°y ·∫£nh", "url": "https://shopee.vn/search?keyword=M√°y%20·∫£nh"},
    {"name": "M√°y t√≠nh b·∫£ng", "url": "https://shopee.vn/search?keyword=M√°y%20t√≠nh%20b·∫£ng"},
    {"name": "Headphone", "url": "https://shopee.vn/search?keyword=Headphone"},
    {"name": "Loa", "url": "https://shopee.vn/search?keyword=Loa"},
    {"name": "Ph·ª• ki·ªán ƒëi·ªán tho·∫°i",
        "url": "https://shopee.vn/search?keyword=Ph·ª•%20ki·ªán%20ƒëi·ªán%20tho·∫°i"},
    {"name": "S√°ch", "url": "https://shopee.vn/search?keyword=S√°ch"},
]

# --- H√ÄM DELAY TH√îNG MINH ---


def smart_delay(action_type='normal'):
    """
    T·∫°o delay ng·∫´u nhi√™n gi·ªëng ng∆∞·ªùi d√πng th·∫≠t
    """
    delays = {
        'quick': (1.5, 3),
        'normal': (3, 7),
        'careful': (5, 12),
        'wait': (10, 20)
    }

    min_delay, max_delay = delays.get(action_type, (3, 7))
    time.sleep(random.uniform(min_delay, max_delay))


# --- INIT BROWSER ---
# --- GLOBAL BROWSER INSTANCE ---
GLOBAL_PAGE = None


def get_browser_instance():
    global GLOBAL_PAGE
    if GLOBAL_PAGE:
        return GLOBAL_PAGE

    co = ChromiumOptions()
    co.set_user_agent(
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    co.set_argument('--disable-blink-features=AutomationControlled')
    co.set_argument('--no-sandbox')
    co.set_argument('--disable-dev-shm-usage')
    co.set_argument('--start-maximized')
    # Use a specific user data folder to save login session if desired
    co.set_user_data_path(r'./chrome_profile')

    GLOBAL_PAGE = ChromiumPage(addr_or_opts=co)

    # --- LOGIN WAIT LOGIC ---
    print("\n‚ö†Ô∏è QUAN TR·ªåNG - H√ÉY X·ª¨ L√ù TR∆Ø·ªöC KHI TI·∫æP T·ª§C:")
    print("   1. ƒêƒÉng nh·∫≠p t√†i kho·∫£n Shopee (B·∫ÆT BU·ªòC ƒê·ªÇ √çT B·ªä CAPTCHA H∆†N!)")
    print("   2. Ho√†n th√†nh captcha/x√°c minh n·∫øu c√≥")
    print("   3. Ch∆∞∆°ng tr√¨nh s·∫Ω t·ª± ƒë·ªông ti·∫øp t·ª•c sau 20 gi√¢y...")
    GLOBAL_PAGE.get('https://shopee.vn')
    time.sleep(20)  # Time for manual login

    return GLOBAL_PAGE


def close_browser():
    """ƒê√≥ng tr√¨nh duy·ªát Chrome"""
    global GLOBAL_PAGE
    if GLOBAL_PAGE:
        try:
            GLOBAL_PAGE.quit()
            GLOBAL_PAGE = None
            logging.info("‚úÖ ƒê√£ ƒë√≥ng Chrome")
        except Exception as e:
            logging.error(f"‚ùå L·ªói ƒë√≥ng Chrome: {e}")


def crawl_category_shopee(cat, cookies=None, max_pages=5, retries=2):
    url = cat['url']
    name = cat['name']

    try:
        page = get_browser_instance()
    except Exception as e:
        logging.error(f"‚ùå L·ªói kh·ªüi t·∫°o tr√¨nh duy·ªát: {e}")
        return []

    products = []

    logging.info(f"üöÄ B·∫Øt ƒë·∫ßu crawl Shopee: {name}")

    try:
        if page.url != 'https://shopee.vn/':
            page.get('https://shopee.vn')
        time.sleep(2)

        # Start listener
        page.listen.start('search_items')

        page.get(url)
        logging.info(f"‚úÖ ƒê√£ v√†o URL: {url}")
        time.sleep(5)

    except Exception as e:
        logging.error(f"‚ùå L·ªói truy c·∫≠p {name}: {e}")
        page.quit()
        return []

    for page_num in range(1, max_pages + 1):
        logging.info(f"--- ƒêang x·ª≠ l√Ω Trang {page_num} ({name}) ---")

        # Check ch·∫∑n
        if page.ele('text:Trang kh√¥ng kh·∫£ d·ª•ng', timeout=1) or page.ele('text:Traffic Error', timeout=1):
            logging.warning("üõë B·ªä CH·∫∂N! H√£y x·ª≠ l√Ω captcha th·ªß c√¥ng.")
            input("üëâ Nh·∫•n Enter sau khi x·ª≠ l√Ω ƒë·ªÉ ti·∫øp t·ª•c...")
            page.listen.start('search_items')
            page.refresh()
            time.sleep(5)

        # Scroll
        page.scroll.to_bottom()
        smart_delay('quick')

        # L·∫•y items t·ª´ listener
        found_items_in_page = 0
        try:
            for packet in page.listen.steps(timeout=8):
                try:
                    body = packet.response.body
                    if not isinstance(body, dict):
                        continue

                    items = body['items']

                    for item in items:
                        basic = item.get('item_basic', item)
                        itemid = basic.get('itemid')
                        shopid = basic.get('shopid')

                        raw_rating = basic.get(
                            'item_rating', {}).get('rating_star', 0)
                        try:
                            r = float(
                                raw_rating) if raw_rating is not None else 0.0
                            rating_star_val = math.floor(r * 10) / 10
                        except Exception:
                            rating_star_val = raw_rating

                        price = (basic.get('price', 0) or 0) / 100000

                        product = {
                            "crawl_date": datetime.datetime.now().strftime("%Y-%m-%d"),
                            "platform": "Shopee",
                            "category_name": name,
                            'id': str(itemid),
                            'itemid': str(itemid),
                            'shopid': str(shopid),
                            'name': basic.get('name', 'N/A'),
                            'price': price,
                            'original_price': (basic.get('price_before_discount', 0) or 0) / 100000,
                            'discount': basic.get('discount', ''),
                            'rating_average': rating_star_val,
                            'review_count': basic.get('cmt_count'),
                            'liked_count': basic.get('liked_count', 0),
                            'quantity_sold_value': basic.get('sold', 0),
                            'quantity_historical_sold_value': basic.get('historical_sold', 0),
                            'brand': str(basic.get('brand')),
                            'location': basic.get('shop_location', 'N/A'),
                            'seller_name': basic.get('shop_name'),
                            'url': f"https://shopee.vn/product/{shopid}/{itemid}"
                        }

                        # Check duplicate
                        if not any(p['id'] == product['id'] for p in products):
                            products.append(product)
                            found_items_in_page += 1

                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è L·ªói ƒë·ªçc g√≥i tin: {e}")
                    continue

        except Exception as e:
            logging.error(f"‚ùå L·ªói listener: {e}")

        logging.info(f"-> T√¨m th·∫•y {found_items_in_page} s·∫£n ph·∫©m m·ªõi.")

        if found_items_in_page == 0:
            logging.warning(
                "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m. C√≥ th·ªÉ h·∫øt trang ho·∫∑c l·ªói.")
            if page_num == 1:
                pass

        # Next page
        if page_num < max_pages:
            try:
                btn_next = page.ele(
                    'css:.shopee-icon-button--right:not(.shopee-button-disabled)', timeout=2)
                if btn_next:
                    btn_next.click()
                    smart_delay('careful')
                else:
                    logging.info("üõë Kh√¥ng th·∫•y n√∫t Next ho·∫∑c ƒë√£ h·∫øt trang.")
                    break
            except Exception as e:
                logging.error(f"üõë L·ªói next page: {e}")
                break

    return products


if __name__ == "__main__":
    try:
        crawl_all_generic(
            platform_name="Shopee",
            categories=SHOPEE_CATEGORIES,
            crawl_category_func=crawl_category_shopee,
            get_cookies_func=None,
            output_dir=SHOPEE_RAW_DIR,
            category_dir=SHOPEE_CATEGORY_DIR,
            max_pages=MAX_PAGES,
            retries=2,
            sleep_min=SLEEP_MIN,
            sleep_max=SLEEP_MAX,
            file_prefix="shopee"
        )
    finally:
        close_browser()
