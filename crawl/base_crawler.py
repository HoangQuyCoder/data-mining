import os
import time
import random
import pandas as pd
import datetime
import logging
from tqdm import tqdm
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager


def get_fresh_cookies(
    url: str = "https://tiki.vn",
    headless: bool = True,
    scroll: bool = False,
    wait_time: int = 10,
) -> dict:
    """
    H√†m chung l·∫•y cookies t·ª´ m·ªôt URL b·∫•t k·ª≥.

    Args:
        url: URL c·∫ßn l·∫•y cookies (m·∫∑c ƒë·ªãnh tiki.vn)
        headless: Ch·∫ø ƒë·ªô headless (m·∫∑c ƒë·ªãnh True)
        scroll: C√≥ scroll trang hay kh√¥ng (m·∫∑c ƒë·ªãnh False)
        wait_time: Th·ªùi gian ch·ªù t·∫£i trang (m·∫∑c ƒë·ªãnh 10 gi√¢y)

    Returns:
        Dict cookies ho·∫∑c {} n·∫øu l·ªói
    """
    options = Options()
    if headless:
        options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
    )

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        driver.get(url)
        time.sleep(wait_time)

        if scroll:
            driver.execute_script(
                "window.scrollTo(0, document.body.scrollHeight / 2);")
            time.sleep(5)

        cookies = {c['name']: c['value'] for c in driver.get_cookies()}
        logging.info(
            f"‚úÖ L·∫•y cookies th√†nh c√¥ng: {len(cookies)} cookies t·ª´ {url}")
        return cookies
    except Exception as e:
        logging.error(f"L·ªói l·∫•y cookies t·ª´ {url}: {e}")
        return {}
    finally:
        driver.quit()


def crawl_all_generic(
    *,
    platform_name: str,
    categories: list,
    crawl_category_func,
    output_dir: str,
    get_cookies_func=None,
    category_dir: str | None = None,
    max_pages: int = 20,
    retries: int = 2,
    sleep_min: int = 8,
    sleep_max: int = 15,
    file_prefix: str | None = None,
):
    """
    Generic crawl_all template

    L∆∞u d·ªØ li·ªáu v√†o:
    - File t·ªïng h·ª£p t·∫•t c·∫£ danh m·ª•c: output_dir
    - File ri√™ng t·ª´ng danh m·ª•c: category_dir (n·∫øu ƒë∆∞·ª£c cung c·∫•p)
    """

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M")
    all_products = []

    cookies = None
    if get_cookies_func:
        cookies = get_cookies_func()

    logging.info(f"üöÄ B·∫Øt ƒë·∫ßu crawl {platform_name}")

    os.makedirs(output_dir, exist_ok=True)
    if category_dir:
        os.makedirs(category_dir, exist_ok=True)

    prefix = file_prefix or platform_name.lower()

    for cat in tqdm(categories, desc=f"Danh m·ª•c {platform_name}"):
        try:
            prods = crawl_category_func(
                cat,
                cookies=cookies,
                max_pages=max_pages,
                retries=retries
            )

            if prods:
                all_products.extend(prods)

                # L∆∞u t·ª´ng danh m·ª•c v√†o file ri√™ng
                if category_dir:
                    cat_name = cat.get("name", "unknown").replace(
                        "/", "_").replace(" ", "_")
                    cat_filename = os.path.join(
                        category_dir,
                        f"{prefix}_{cat_name}_{timestamp}.json"
                    )
                    pd.DataFrame(prods).to_json(
                        cat_filename,
                        orient="records",
                        force_ascii=False,
                        indent=2
                    )
                    logging.info(
                        f"{cat['name']}: L∆∞u {len(prods)} s·∫£n ph·∫©m ‚Üí {cat_filename}")

        except Exception as e:
            logging.error(f"‚ùå L·ªói category {cat}: {e}")

        time.sleep(random.uniform(sleep_min, sleep_max))

    if not all_products:
        logging.warning(f"{platform_name}: Kh√¥ng c√≥ d·ªØ li·ªáu")
        return

    # L∆∞u file t·ªïng h·ª£p t·∫•t c·∫£ danh m·ª•c
    filename = os.path.join(
        output_dir,
        f"{prefix}_all_{timestamp}.json"
    )

    pd.DataFrame(all_products).to_json(
        filename,
        orient="records",
        force_ascii=False,
        indent=2
    )

    logging.info(
        f"{platform_name}: L∆∞u {len(all_products)} s·∫£n ph·∫©m (t·ªïng) ‚Üí {filename}"
    )
