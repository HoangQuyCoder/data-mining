import pandas as pd
import numpy as np
import json
import re
import os
from datetime import datetime


class ValueExtractor:
    """L·ªõp tr√≠ch xu·∫•t v√† chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã t·ª´ d·ªØ li·ªáu th√¥"""

    @staticmethod
    def extract_price(value):
        """Tr√≠ch xu·∫•t gi√° tr·ªã s·ªë t·ª´ chu·ªói gi√° (vd: '499.000 ‚Ç´' -> 499000)"""
        if value is None or pd.isna(value):
            return None

        if isinstance(value, (int, float)):
            return float(value)

        value = re.sub(r"[^\d]", "", str(value))
        return float(value) if value else None

    @staticmethod
    def extract_discount(value):
        """Tr√≠ch xu·∫•t t·ª∑ l·ªá gi·∫£m gi√° (vd: '17% Off' -> 17)"""
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)
        match = re.search(r"\d+", value)
        return float(match.group()) if match else None

    @staticmethod
    def extract_sold_value(sold_text):
        """Tr√≠ch xu·∫•t s·ªë l∆∞·ª£ng b√°n (vd: '1.2K Sold' -> 1200)"""
        try:
            if pd.isna(sold_text):
                return None
        except (TypeError, ValueError):
            pass

        if sold_text is None:
            return None

        sold_text = str(sold_text).upper().strip()
        match = re.search(r'([\d.]+)\s*([KMB]?)', sold_text)

        if match:
            value = float(match.group(1))
            unit = match.group(2)

            if unit == 'K':
                return int(value * 1000)
            elif unit == 'M':
                return int(value * 1000000)
            elif unit == 'B':
                return int(value * 1000000000)
            else:
                return int(value)

        return None

    @staticmethod
    def safe_to_numeric(value):
        """
        √âp ki·ªÉu an to√†n:
        - number -> number
        - string s·ªë -> number
        - dict / list / kh√°c -> NaN
        """
        if isinstance(value, (int, float)):
            return value

        if isinstance(value, str):
            try:
                return float(value)
            except:
                return None

        return None


class ProductNormalizer:
    """L·ªõp chu·∫©n h√≥a d·ªØ li·ªáu s·∫£n ph·∫©m t·ª´ c√°c platform kh√°c nhau"""

    PLATFORM_MAPPING = {
        "tiki": {
            "current_price": "price",
            "original_price": "original_price",
            "discount_rate": "discount_rate",
            "rating_average": "rating_average",
            "num_reviews": "review_count",
            "quantity_sold": "quantity_sold_value",
            "quantity_sold_text": "quantity_sold_text",
            "brand": "brand",
            "seller_location": "location",
        },
        "lazada": {
            "current_price": "price",
            "original_price": "original_price",
            "discount_rate": "discount",
            "rating_average": "rating",
            "num_reviews": "review_count",
            "quantity_sold": "sold_value",
            "quantity_sold_text": "sold_text",
            "brand": "brand",
            "seller_location": "location",
        },
        "shopee": {
            "current_price": "price",
            "original_price": "original_price",
            "discount_rate": "discount_rate",
            "rating_average": "rating_average",
            "num_reviews": "review_count",
            "quantity_sold": "quantity_sold_value",
            "quantity_sold_text": "quantity_sold_text",
            "brand": "brand",
            "seller_location": "location",
        },
    }

    @classmethod
    def normalize_product(cls, item: dict) -> dict:
        """Chu·∫©n h√≥a m·ªôt s·∫£n ph·∫©m t·ª´ b·∫•t k·ª≥ platform n√†o"""
        platform = item.get("platform", "").lower()

        normalized = {
            "crawl_date": item.get("crawl_date"),
            "platform": item.get("platform"),
            "category": item.get("category_name"),
            "id": item.get("id"),
            "product_name": item.get("name"),
            "current_price": None,
            "original_price": None,
            "discount_rate": None,
            "rating_average": None,
            "num_reviews": None,
            "quantity_sold": None,
            "quantity_sold_text": None,
            "brand": None,
            "seller_location": None,
            "product_url": item.get("url"),
        }

        # √Åp d·ª•ng mapping cho platform
        if platform in cls.PLATFORM_MAPPING:
            mapping = cls.PLATFORM_MAPPING[platform]
            for standard_key, source_key in mapping.items():
                if standard_key in normalized:
                    normalized[standard_key] = item.get(source_key)

        return normalized

    @classmethod
    def normalize_dataset(cls, data: list[dict]) -> pd.DataFrame:
        """Chu·∫©n h√≥a to√†n b·ªô dataset"""
        normalized_data = [cls.normalize_product(item) for item in data]
        df = pd.DataFrame(normalized_data)
        return df


class DataCleaner:
    """L·ªõp ch√≠nh ƒë·ªÉ l√†m s·∫°ch v√† x·ª≠ l√Ω d·ªØ li·ªáu merged"""

    # Danh s√°ch c·ªôt cu·ªëi c√πng c·∫ßn gi·ªØ l·∫°i
    FINAL_COLUMNS = [
        'id', 'crawl_date', 'platform', 'category', 'product_name',
        'current_price', 'discount_rate',
        'rating_average', 'quality_category', 'num_reviews', 'popularity_category',
        'quantity_sold',
        'brand', 'seller_location',
        'product_url', 'rating_average_missing', 'discount_rate_missing'
    ]

    # C·ªôt text c·∫ßn ƒëi·ªÅn gi√° tr·ªã m·∫∑c ƒë·ªãnh
    TEXT_COLUMNS = [
        "quantity_sold_text",
        "brand",
        "seller_location"
    ]

    # Key ƒë·ªÉ lo·∫°i b·ªè duplicate
    DEDUP_KEYS = ["platform", "id"]

    def __init__(self, input_file, output_file=None):
        """Kh·ªüi t·∫°o DataCleaner"""
        self.input_file = input_file
        self.output_file = output_file or self._get_default_output_file()
        # self.df = None
        self.raw_data = None

    def _get_default_output_file(self):
        """L·∫•y ƒë∆∞·ªùng d·∫´n output m·∫∑c ƒë·ªãnh"""
        base = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        return os.path.join(base, 'data/clean/merged_cleaned_data.json')

    def load_data(self):
        """B∆∞·ªõc 1: ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON"""
        print(f"üìÇ ƒêang ƒë·ªçc file: {self.input_file}")
        with open(self.input_file, 'r', encoding='utf-8') as f:
            self.raw_data = json.load(f)

        print(f"‚úì ƒê√£ load {len(self.raw_data)} records\n")

    def normalize_data(self):
        """B∆∞·ªõc 2: Chu·∫©n h√≥a t√™n c·ªôt t·ª´ c√°c platform kh√°c nhau"""
        print("üîß B∆∞·ªõc 1: Chu·∫©n h√≥a d·ªØ li·ªáu...")
        if self.raw_data is None:
            raise ValueError("Raw data is not loaded. Call load_data() first.")
        self.df = ProductNormalizer.normalize_dataset(self.raw_data)
        print(f"‚úì ƒê√£ chu·∫©n h√≥a {len(self.df)} records\n")

    def clean_prices(self):
        """B∆∞·ªõc 3: X·ª≠ l√Ω gi√° ti·ªÅn"""
        print("üí∞ B∆∞·ªõc 2: X·ª≠ l√Ω gi√° ti·ªÅn...")
        if 'current_price' in self.df.columns:
            self.df['current_price'] = self.df['current_price'].apply(
                ValueExtractor.extract_price
            )
        if 'original_price' in self.df.columns:
            self.df['original_price'] = self.df['original_price'].apply(
                ValueExtractor.extract_price
            )

        self.df[['current_price', 'original_price']] = self.df[
            ['current_price', 'original_price']
        ].apply(pd.to_numeric, errors='coerce')

        print(f"‚úì Gi√° ti·ªÅn ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n")

    def clean_discount(self):
        """B∆∞·ªõc 4: X·ª≠ l√Ω discount rate"""
        print("üìâ B∆∞·ªõc 3: X·ª≠ l√Ω discount rate...")
        if 'discount_rate' in self.df.columns:
            self.df['discount_rate'] = self.df['discount_rate'].apply(
                ValueExtractor.extract_discount
            )
        print(f"‚úì Discount rate ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n")

    def clean_ratings(self):
        """B∆∞·ªõc 5: X·ª≠ l√Ω rating v√† review count"""
        print("‚≠ê B∆∞·ªõc 4: X·ª≠ l√Ω rating v√† s·ªë review...")
        if 'rating_average' in self.df.columns:
            self.df['rating_average'] = self.df['rating_average'].apply(
                ValueExtractor.safe_to_numeric
            )

        if 'num_reviews' in self.df.columns:
            self.df['num_reviews'] = self.df['num_reviews'].apply(
                ValueExtractor.safe_to_numeric
            )

        print(f"‚úì Rating v√† review_count ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n")

    def clean_quantity_sold(self):
        """B∆∞·ªõc 6: X·ª≠ l√Ω s·ªë l∆∞·ª£ng ƒë√£ b√°n"""
        print("üì¶ B∆∞·ªõc 5: X·ª≠ l√Ω s·ªë l∆∞·ª£ng ƒë√£ b√°n...")
        if 'quantity_sold_text' in self.df.columns:
            self.df['quantity_sold'] = self.df['quantity_sold_text'].apply(
                lambda x: ValueExtractor.extract_sold_value(
                    x) if isinstance(x, str) else None
            )
        print(f"‚úì Quantity sold ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n")

    def clean_brand(self):
        """B∆∞·ªõc 6.5: X·ª≠ l√Ω brand - normalize c√°c bi·∫øn th·ªÉ 'No Brand'"""
        print("üè∑Ô∏è  B∆∞·ªõc 5.5: X·ª≠ l√Ω brand...")
        if 'brand' in self.df.columns:
            def normalize_brand(value):
                if value is None or pd.isna(value):
                    return "UNKNOWN"

                value_str = str(value).strip()
                # Normalize c√°c bi·∫øn th·ªÉ c·ªßa "No Brand"
                if value_str.lower() in ["no brand", "no.brand", "nobrand", "none", "n/a", ""]:
                    return "UNKNOWN"

                return value_str if value_str else "UNKNOWN"

            self.df['brand'] = self.df['brand'].apply(normalize_brand)
        print(f"‚úì Brand ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a\n")

    def handle_missing_data(self):
        """B∆∞·ªõc 7: X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu"""
        print("üßπ B∆∞·ªõc 6: X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu...")
        print(f"  - D·ªØ li·ªáu thi·∫øu tr∆∞·ªõc x·ª≠ l√Ω:")
        print(self.df.isnull().sum())

        # X·ª≠ l√Ω rating_average
        if 'rating_average' in self.df.columns:
            self.df["rating_average_missing"] = self.df["rating_average"].isna().astype(
                int)
            self.df["rating_average"].fillna(
                self.df["rating_average"].median(), inplace=True
            )

        # X·ª≠ l√Ω discount_rate
        if 'discount_rate' in self.df.columns:
            self.df["discount_rate_missing"] = self.df["discount_rate"].isna().astype(
                int)
            self.df["discount_rate"].fillna(
                self.df["discount_rate"].median(), inplace=True
            )

        # X·ª≠ l√Ω num_reviews v√† quantity_sold
        if 'num_reviews' in self.df.columns:
            self.df['num_reviews'] = self.df['num_reviews'].fillna(0)
        if 'quantity_sold' in self.df.columns:
            self.df['quantity_sold'] = self.df['quantity_sold'].fillna(0)

        self.df['original_price'] = pd.to_numeric(
            self.df['original_price'], errors="coerce")

        # ƒêi·ªÅn gi√° tr·ªã m·∫∑c ƒë·ªãnh cho c·ªôt text
        self.df[self.TEXT_COLUMNS] = self.df[self.TEXT_COLUMNS].fillna(
            "UNKNOWN")
        print(f"‚úì D·ªØ li·ªáu thi·∫øu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω\n")

    def remove_duplicates_and_invalid(self):
        """B∆∞·ªõc 8: Lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p v√† kh√¥ng h·ª£p l·ªá"""
        print("üóëÔ∏è  B∆∞·ªõc 7: Lo·∫°i b·ªè d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá...")
        print(f"  - S·ªë record tr∆∞·ªõc khi lo·∫°i b·ªè: {len(self.df)}")

        # S·∫Øp x·∫øp theo ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu
        self.df = self.df.sort_values(
            by=[
                "quantity_sold",
                "num_reviews",
                "rating_average_missing" if "rating_average_missing" in self.df.columns else "id"
            ],
            ascending=[False, False, True]
        )

        # Lo·∫°i b·ªè tr√πng l·∫∑p
        self.df = self.df.drop_duplicates(
            subset=self.DEDUP_KEYS,
            keep="first"
        )
        self.df = self.df.reset_index(drop=True)

        # Lo·∫°i b·ªè record kh√¥ng c√≥ t√™n s·∫£n ph·∫©m
        if 'product_name' in self.df.columns:
            self.df = self.df[self.df['product_name'].notna()]

        # Lo·∫°i b·ªè record c√≥ gi√° <= 0 ho·∫∑c null
        if 'current_price' in self.df.columns:
            self.df = self.df[self.df['current_price'] > 0]
            self.df = self.df[self.df['current_price'].notna()]

        print(f"  - S·ªë record sau khi lo·∫°i b·ªè: {len(self.df)}\n")

    def select_final_columns(self):
        """B∆∞·ªõc 9: Ch·ªçn c√°c c·ªôt c·∫ßn thi·∫øt"""
        print("üìã B∆∞·ªõc 8: Ch·ªçn c·ªôt c·∫ßn thi·∫øt...")

        # Ch·ªâ l·∫•y c√°c c·ªôt t·ªìn t·∫°i
        available_columns = [
            col for col in self.FINAL_COLUMNS if col in self.df.columns]
        self.df = self.df[available_columns]

        print(f"‚úì C·ªôt cu·ªëi c√πng: {len(self.df.columns)} c·ªôt\n")

    def save_data(self):
        """B∆∞·ªõc 10: L∆∞u d·ªØ li·ªáu"""
        print(f"üíæ B∆∞·ªõc 9: L∆∞u d·ªØ li·ªáu...")
        print(f"  - Output file: {self.output_file}")

        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        os.makedirs(os.path.dirname(self.output_file), exist_ok=True)

        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(self.df.to_dict('records'), f,
                      ensure_ascii=False, indent=2)

        print(f"‚úì D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u\n")

    def print_statistics(self):
        """B∆∞·ªõc 11: In th·ªëng k√™ t√≥m t·∫Øt"""
        print("=" * 60)
        print("üìä TH·ªêNG K√ä T√ìM T·∫ÆT")
        print("=" * 60)
        print(f"T·ªïng records: {len(self.df)}")

        print(f"\nTh√¥ng tin gi√°:")
        if 'current_price' in self.df.columns:
            print(
                f"  - Gi√° hi·ªán t·∫°i: {self.df['current_price'].min():.0f} - {self.df['current_price'].max():.0f}")
            print(f"  - Trung b√¨nh: {self.df['current_price'].mean():.0f}")

        print(f"\nTh√¥ng tin ƒë√°nh gi√°:")
        if 'rating_average' in self.df.columns:
            print(
                f"  - Rating trung b√¨nh: {self.df['rating_average'].mean():.2f}")
        if 'num_reviews' in self.df.columns:
            print(
                f"  - Review trung b√¨nh: {self.df['num_reviews'].mean():.0f}")

        if 'platform' in self.df.columns:
            print(f"\nPlatform:")
            print(self.df['platform'].value_counts())

        if 'category' in self.df.columns:
            print(f"\nTop 5 Categories:")
            print(self.df['category'].value_counts().head())

        if 'brand' in self.df.columns:
            print(f"\nTop 5 Brands:")
            print(self.df['brand'].value_counts().head())

        if 'quality_category' in self.df.columns:
            print(f"\nQuality Distribution:")
            print(self.df['quality_category'].value_counts())

        if 'popularity_category' in self.df.columns:
            print(f"\nPopularity Distribution:")
            print(self.df['popularity_category'].value_counts())

        print("=" * 60)
        print("\nüí° ƒê·ªÉ xem bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a, ch·∫°y:")
        print("   python main/visualize_cleaning_results.py")
        print("=" * 60)

    def clean(self):
        """Th·ª±c hi·ªán to√†n b·ªô qu√° tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu"""
        print("\nüöÄ B·∫ÆT ƒê·∫¶U L√ÄM S·∫†CH D·ªÆ LI·ªÜU")
        print("=" * 60 + "\n")

        self.load_data()
        self.normalize_data()
        self.clean_prices()
        self.clean_discount()
        self.clean_ratings()
        self.clean_quantity_sold()
        self.clean_brand()
        self.handle_missing_data()
        self.remove_duplicates_and_invalid()
        self.select_final_columns()
        self.save_data()
        self.print_statistics()

        print("\n‚úÖ HO√ÄN TH√ÄNH!\n")
        return self.df


# H√†m wrapper ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
def clean_merged_data(input_file, output_file=None):
    """
    L√†m s·∫°ch d·ªØ li·ªáu t·ª´ file merged_raw_data.json

    Parameters:
    - input_file: ƒë∆∞·ªùng d·∫´n file .json ƒë·∫ßu v√†o
    - output_file: ƒë∆∞·ªùng d·∫´n file output (m·∫∑c ƒë·ªãnh: data/clean/merged_cleaned_data.json)
    """
    cleaner = DataCleaner(input_file, output_file)
    return cleaner.clean()


if __name__ == "__main__":
    # ƒê∆∞·ªùng d·∫´n input/output
    base = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    input_file = os.path.join(
        base, 'data/preliminary/merged_preliminary_data.json')
    output_file = os.path.join(base, 'data/clean/merged_cleaned_data.json')

    # S·ª≠ d·ª•ng class DataCleaner
    cleaner = DataCleaner(input_file, output_file)
    df_cleaned = cleaner.clean()
